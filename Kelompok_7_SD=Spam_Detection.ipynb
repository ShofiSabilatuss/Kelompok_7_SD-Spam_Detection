{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e267f39",
      "metadata": {
        "id": "0e267f39"
      },
      "source": [
        "## Penjelasan Dataset yang digunakan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f255f5f0",
      "metadata": {
        "id": "f255f5f0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed6e93be",
      "metadata": {
        "id": "ed6e93be"
      },
      "source": [
        "## Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "61303d4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61303d4f",
        "outputId": "7243a863-7918-402e-ee75-4718bcd49715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File tidak ditemukan. Pastikan path file sudah benar.\n",
            "File berhasil dibaca.\n",
            "5 baris pertama data:\n",
            "  Label                                               Teks\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "\n",
            "Informasi Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Label   5572 non-null   object\n",
            " 1   Teks    5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "\n",
            "Distribusi Label:\n",
            "Label\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Semester_7/NLP/spam.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path, encoding='latin-1')\n",
        "except FileNotFoundError:\n",
        "    print(\"File tidak ditemukan. Pastikan path file sudah benar.\")\n",
        "    df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "    print(\"File berhasil dibaca.\")\n",
        "df = df.iloc[:, [0, 1]]\n",
        "df.columns = ['Label', 'Teks']\n",
        "print(\"5 baris pertama data:\")\n",
        "print(df.head())\n",
        "print(\"\\nInformasi Data:\")\n",
        "df.info()\n",
        "df['Label'] = df['Label'].map({'ham': 0, 'spam': 1})\n",
        "print(\"\\nDistribusi Label:\")\n",
        "print(df['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72850f37",
      "metadata": {
        "id": "72850f37"
      },
      "source": [
        "## Data Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "86552683",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86552683",
        "outputId": "62d19370-e7a4-4391-bafe-3bca13a43957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contoh Teks Setelah Pra-pemrosesan:\n",
            "                                                Teks  \\\n",
            "0  Go until jurong point, crazy.. Available only ...   \n",
            "1                      Ok lar... Joking wif u oni...   \n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3  U dun say so early hor... U c already then say...   \n",
            "4  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                         Teks_Bersih  Label  \n",
            "0  go jurong point crazy available bugis n great ...      0  \n",
            "1                            ok lar joking wif u oni      0  \n",
            "2  free entry 2 wkly comp win fa cup final tkts 2...      1  \n",
            "3                u dun say early hor u c already say      0  \n",
            "4        nah dont think goes usf lives around though      0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "df['Teks_Bersih'] = df['Teks'].apply(preprocess_text)\n",
        "print(\"\\nContoh Teks Setelah Pra-pemrosesan:\")\n",
        "print(df[['Teks', 'Teks_Bersih', 'Label']].head())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd39c6c5",
        "outputId": "594e7394-ba67-4244-f383-bd77c0f8a483"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "df['Teks_Bersih'] = df['Teks'].apply(preprocess_text)\n",
        "print(\"\\nContoh Teks Setelah Pra-pemrosesan:\")\n",
        "print(df[['Teks', 'Teks_Bersih', 'Label']].head())"
      ],
      "id": "bd39c6c5",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contoh Teks Setelah Pra-pemrosesan:\n",
            "                                                Teks  \\\n",
            "0  Go until jurong point, crazy.. Available only ...   \n",
            "1                      Ok lar... Joking wif u oni...   \n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3  U dun say so early hor... U c already then say...   \n",
            "4  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                         Teks_Bersih  Label  \n",
            "0  go jurong point crazy available bugis n great ...      0  \n",
            "1                            ok lar joking wif u oni      0  \n",
            "2  free entry 2 wkly comp win fa cup final tkts 2...      1  \n",
            "3                u dun say early hor u c already say      0  \n",
            "4        nah dont think goes usf lives around though      0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d8543c",
      "metadata": {
        "id": "a3d8543c"
      },
      "source": [
        "## Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "661d9c68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "661d9c68",
        "outputId": "82c0f434-290e-4d58-9d50-415a6e55a061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bentuk Matriks Fitur (Baris, Kolom): (5572, 5000)\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = df['Teks_Bersih']\n",
        "y = df['Label']\n",
        "X_transformed = tfidf_vectorizer.fit_transform(X)\n",
        "print(\"\\nBentuk Matriks Fitur (Baris, Kolom):\", X_transformed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_transformed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nModel Naive Bayes berhasil dilatih.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OeZK588ylek",
        "outputId": "4fd4f264-b049-492d-cb29-1e4ac98c646f"
      },
      "id": "2OeZK588ylek",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Naive Bayes berhasil dilatih.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3829b27",
      "metadata": {
        "id": "d3829b27"
      },
      "source": [
        "## Data Evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5c1e226b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c1e226b",
        "outputId": "af60ab45-1389-4b74-da22-6268928b87de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Akurasi Model: 97.85%\n",
            "\n",
            "Matriks Kebingungan (Confusion Matrix):\n",
            "[[966   0]\n",
            " [ 24 125]]\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       966\n",
            "           1       1.00      0.84      0.91       149\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.92      0.95      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n✅ Akurasi Model: {accuracy*100:.2f}%\")\n",
        "print(\"\\nMatriks Kebingungan (Confusion Matrix):\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(class_report)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "credit_scoring",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}